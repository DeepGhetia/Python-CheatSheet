1. shuffle is most costly operation hence avoid wide operation or get the data to that stage where data is less hence little shuffle.
there are types of optimization - 
    1. code level
        - use cache
        - use reducebykey over groupbykey
        - use broadcast var over join for dimenasion tables
        - select vs wothcolumn for more columns
    2. cluster level (executors) -

cache (very imp)- 
commands (DF):- 
1. df = df1.cache()
2. df.unpersist() //uncache()

DF
    df.cache()       // lazy
    df.count()       // slow (computes + caches)
    df.count()       // fast
SPARK SQL
    CACHE TABLE table1;  -- eager, materializes now (can take time)
    SELECT count(*) FROM table1;  -- fast
    SELECT * FROM table1;         -- fast
scenario where cache can have less performance - 
1. say u have an extrenal table whee file format is parquet and since count of recs are part of metadata hence the result is fast
when compare to cacehd data as in cache scenario we have to scan the data though it is fast as process local

Persist - 
from pyspark.storagelevel import storagelevel

df1 = df.persist(StorageLevel(param1,param2,param3,param4,param5))
param - 
1.disk - True/False
2.mem -  True/False
3.offheap -  True/False
4.serialized/de -  True/False
5.replicaion -  True/False

to uncache or unpersist - unpersist()

***logical plan
1. spark pushes filter pushes up in order called as predicate push down
2. okay so process local means same exe and node local means same machine or node
3. in case of cache process local is mostly cahced data and other in node local 